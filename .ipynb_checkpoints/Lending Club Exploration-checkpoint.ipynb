{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n",
    "from sklearn import linear_model\n",
    "import seaborn as sb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./loan.csv\"\n",
    "inputDf = pd.read_csv(path, \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectedCols = inputDf[[\"loan_amnt\", \"funded_amnt\", \"term\", \"int_rate\", \"grade\", \"annual_inc\", \"issue_d\",\n",
    "\"dti\", \"revol_bal\", \"total_pymnt\", \"loan_status\"]]\n",
    "selectedCols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse data into numeric where possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termDummies = pd.get_dummies(selectedCols[\"term\"])\n",
    "selectedCols = termDummies.join(selectedCols.drop(columns = [\"term\"]))\n",
    "selectedCols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedCols[\"origYear\"] = selectedCols[\"issue_d\"].str.extract(\"\\w{3}-(\\d{4})\")\n",
    "selectedCols = selectedCols.drop(columns= [\"issue_d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typedDf = selectedCols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part One - Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at data types\n",
    "typedDf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x=\"grade\", y=\"int_rate\", data=typedDf, kind=\"box\", order = (\"A\", \"B\", \"C\", \"D\", \"E\", \"F\",\"G\"))\n",
    "## worried that grades and interest rates lead to multicolinearity problems\n",
    "## also notice that all grades except A and G have some sort of 'outlier' interest rate at 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert grades to numerics\n",
    "gradeDummies = pd.get_dummies(selectedCols[\"grade\"], prefix=\"grade\")\n",
    "selectedColsNoGrade = typedDf.drop(columns=[\"grade\"])\n",
    "dummiedGradesDf = gradeDummies.join(selectedColsNoGrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummiedGradesDf[\"grade\"] = dummiedGradesDf[\"grade_A\"] * 0 + \\\n",
    "    dummiedGradesDf[\"grade_B\"] * 2 + dummiedGradesDf[\"grade_C\"] * 3 + dummiedGradesDf[\"grade_D\"] * 4  + \\\n",
    "    dummiedGradesDf[\"grade_E\"] * 5 + dummiedGradesDf[\"grade_F\"] * 6 + dummiedGradesDf[\"grade_G\"] * 6\n",
    "dummiedGradesDf = dummiedGradesDf.drop(columns=[\"grade_A\", \"grade_B\", \"grade_C\", \"grade_D\", \"grade_E\", \"grade_F\", \"grade_G\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typedDf = dummiedGradesDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap(typedDf.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funded amt and loan amount are highly correlated\n",
    "\n",
    "interest rate and grade highly correlated (as seen above in box/whisker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### everything is skewed right, except grade which is perfectly balanced\n",
    "### DTI seems to have an outlier, or is 9999 a null placeholder ?\n",
    "normalized = typedDf.copy(deep = True)\n",
    "normalized.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks like dti= 9999 is a null placeholder because there are few values between ~ 100 and that 9999 value\n",
    "dti = typedDf[[\"dti\"]]\n",
    "boxplot = dti.boxplot(column=['dti'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks much better if we remove 9999 - still heavily skewed though.\n",
    "boxplot = dti[dti[\"dti\"] < 900 ].boxplot(column=['dti'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# much nicer if we remove outliers ( > 300)\n",
    "boxplot = dti[dti[\"dti\"] < 300].boxplot(column=['dti'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typedDf = typedDf[typedDf[\"dti\"] < 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, col):\n",
    "    ser = df[[col]]\n",
    "    normalized_ser=(ser-ser.min())/(ser.max()-ser.min())\n",
    "    df.drop(columns=[col])\n",
    "    df[col] = normalized_ser\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeDf = typedDf.copy(deep = True)\n",
    "normalize(normalizeDf, \"loan_amnt\")\n",
    "normalize(normalizeDf, \"funded_amnt\")\n",
    "normalize(normalizeDf, \"int_rate\")\n",
    "normalize(normalizeDf, \"annual_inc\")\n",
    "normalize(normalizeDf, \"dti\")\n",
    "normalize(normalizeDf, \"revol_bal\")\n",
    "normalize(normalizeDf, \"total_pymnt\")\n",
    "normalize(normalizeDf, \"grade\")\n",
    "normalizeDf.boxplot(column=[\"loan_amnt\", \"funded_amnt\", \"int_rate\", \"annual_inc\",\n",
    "                                  \"dti\", \"revol_bal\", \"total_pymnt\", \"grade\"], figsize=(13,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirms suspicions of bad skew.\n",
    "# annual income being the worst offender. nothing to do now other than just keep note for later stages\n",
    "typedDf.skew(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Two - Business Analysis\n",
    "#### footnote - this did not say to balance weight, but this should be balance weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##only look at 36 month loans\n",
    "shortTerm = typedDf[typedDf[\" 36 months\"] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortTerm.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##only look at loans that are no longer alive \n",
    "# assuming that if they are done paying they are in one of three categories below\n",
    "# not sure what: \"Does not meet the credit policy. Status:Charged Off\", \"Does not meet the credit policy. Status:Charged Off\"\n",
    "shortTerm = shortTerm[(shortTerm[\"loan_status\"] == \"Fully Paid\") | (shortTerm[\"loan_status\"] == \"Charged Off\") | \n",
    "                    (shortTerm[\"loan_status\"] == \"Default\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pct loans fully paid ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = shortTerm[\"loan_status\"].value_counts()\n",
    "counts = statuses\n",
    "relFreqs = statuses /shortTerm.size\n",
    "fullyPaidIndex = 1\n",
    "print(\"there are {} loans fully paid, which represents {} loans\".format(counts[fullyPaidIndex], relFreqs[fullyPaidIndex]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### highest rates of default ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultDf = shortTerm[[\"origYear\", \"grade\", \"loan_status\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statusDummies = pd.get_dummies(defaultDf[\"loan_status\"])\n",
    "defaultDf[\"defaulted\"] = (statusDummies[[\"Fully Paid\"]] * - 1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultGroupings = defaultDf.groupby(['origYear', 'grade']).mean()\n",
    "cohorts = defaultGroupings.sort_values(by = \"defaulted\", ascending = False)\n",
    "#defaultGroupings.unstack()\n",
    "maxDefaults = cohorts.iloc[:1,]\n",
    "print(maxDefaults)\n",
    "print(\"the highest default rate of 0.5 was found among 2008 G's !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annualized rate of return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateReturn = shortTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateReturn[\"annualizedRateReturn\"] = np.power((rateReturn[\"total_pymnt\"] / rateReturn[\"funded_amnt\"]), 1/3) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateReturn = rateReturn[[\"annualizedRateReturn\", \"origYear\", \"grade\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateReturn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returnCohorts = rateReturn.groupby(['origYear', 'grade']).mean()\n",
    "returnCohorts = returnCohorts.sort_values(by = \"annualizedRateReturn\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below is a summary of the annualized rate of return for each cohort (grouped by origination year and grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateReturn.groupby(['origYear', 'grade']).mean().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDf = typedDf.copy(deep = True)\n",
    "modelDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first pass using the variables used in data analysis thus far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelDf[\"originationYear\"] = modelDf[\"issue_d\"].str.extract(\"\\w{3}-(\\d{4})\").astype(str).astype(int)\n",
    "#modelDf = modelDf.drop(columns = [\"issue_d\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create features / labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDf = modelDf[(modelDf[\"loan_status\"] == \"Fully Paid\") | (modelDf[\"loan_status\"] == \"Charged Off\") | \n",
    "                    (modelDf[\"loan_status\"] == \"Default\")]\n",
    "statusDummies = pd.get_dummies(modelDf[\"loan_status\"])\n",
    "modelDf[\"defaulted\"] = (statusDummies[[\"Fully Paid\"]] * - 1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = modelDf[\"defaulted\"]\n",
    "features = modelDf.drop(columns=[\"defaulted\", \"loan_status\", \"funded_amnt\", \" 60 months\"])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "freqentist = DummyClassifier(strategy='most_frequent')\n",
    "freqentist.fit(train_features, train_labels)\n",
    "print(\"baseline prediction accuracy is {}\".format(freqentist.score(test_features, test_labels).round(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try multivariate linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression(normalize = False)\n",
    "model = ols.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OLS regression has an R^2 of {}\".format(model.score(test_features, test_labels).round(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this is pretty bad... lets work harder on variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SelectKBest(f_regression).fit_transform(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_regression(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
